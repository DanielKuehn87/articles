\documentclass[xcolor=dvipsnames,11pt]{beamer}

\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{array}
\usepackage{adjustbox}
\usepackage{xspace}
\usepackage{tikz}
\usepackage{color}
\usetikzlibrary{shapes,arrows,backgrounds,fit,positioning,chains,shadows,decorations.pathmorphing,decorations.pathreplacing,matrix}
\usepackage{csquotes}
\usepackage{booktabs}
\usepackage{wasysym}
\usepackage[binary-units=true]{siunitx}
\usepackage{xcolor}
\usepackage{pifont}
\usepackage{dsfont}

\definecolor{tugreen}{cmyk}{0.57, 0, 1.00, 0}
\definecolor{tugreen1}{cmyk}{0.57, 0, 1.00, 0}
\definecolor{tugreen2}{HTML}{667E4D}
\definecolor{tugreen3}{HTML}{72A544}
\definecolor{tugreen4}{HTML}{3A472E}

\usecolortheme{dove}
\usetheme{boxes}
\usefonttheme{structuresmallcapsserif}
\newenvironment{whiteframe}
{
 \usebackgroundtemplate{}
 \begin{frame}
}
{
 \end{frame}
}

\usetikzlibrary{shapes,matrix,positioning,chains,arrows,shadows,decorations.pathmorphing,fit,backgrounds}
\setbeamercolor{itemize item}{fg=tugreen1}
\setbeamercolor{itemize subitem}{fg=tugreen1}
\setbeamertemplate{itemize item}[square]
\setbeamertemplate{footline}[frame number]
\beamertemplatenavigationsymbolsempty

\title{Tutorial: \texttt{OpenML} with R and \texttt{mlr}}
\author{Bernd~Bischl, Joaquin~Vanschoren et al.}
\date{Reisensburg 2015}

\newcommand{\norm}[2][\relax]{\ifx#1\relax\ensuremath{\left\Vert#2\right\Vert}\else\ensuremath{\left\Vert#2\right\Vert_{#1}}\fi}
\newcommand{\ind}{\mathds{1}}
\newcommand{\pred}[1]{\ind\left(#1\right)}
\newcommand{\abs}[1]{\ensuremath{\left| #1 \right|}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\pkg}[1]{\texttt{#1}}
\newcommand{\tarrow}{\textcolor{tugreen1}{{\ding{212}}}\xspace}

% suppress frame numbering, so noframenumbering works
% \setbeamertemplate{frametitle continuation}
%   \begin{frame}[containsverbatim,allowframebreaks,noframenumbering]

\newenvironment{vframe}
{
  \begin{frame}[containsverbatim]
}
{
 \end{frame}
}

\newenvironment{vbframe}
{
  \begin{frame}[containsverbatim,allowframebreaks]
}
{
 \end{frame}
}

\newenvironment{blocki*}
{
  \begin{block}{}\begin{itemize}
}
{
\end{itemize}\end{block}
}

\newenvironment{blocki}[1]
{
  \begin{block}{#1}\begin{itemize}
}
{
\end{itemize}\end{block}
}

\newcommand{\oneliner}[1]{\begin{block}{}\begin{center}\begin{Large}#1\end{Large}\end{center}\end{block}}


\renewcommand<>{\sout}[1]{
  \only#2{\beameroriginal{\sout}{#1}}
  \invisible#2{#1}
}


\AtBeginSection{\frame{\sectionpage}}

\begin{document}
% \usebackgroundtemplate{
%   \begin{tikzpicture}
%     \shade [inner color = white, outer color = gray!30, opacity = 0.8] (\paperwidth,\paperheight) rectangle (0,0);
%     \shade [inner color = white, outer color = gray!10, opacity=.05] (\paperwidth/2,\paperheight/2) circle (3);
%   \end{tikzpicture}
% }

<<opts,include=FALSE,cache=FALSE>>=
library(knitr)
#library(BBmisc)
library(mlr)
#library(ggplot2)
#library(parallelMap)
#library(tikzDevice)
#library(data.table)
#library(gridExtra)
#library(survMisc)
set.seed(1)
options(width = 70)
configureMlr(show.info = FALSE)
configureMlr(show.learner.output = FALSE)
OPENML_EVAL = TRUE

knit_hooks$set(document = function(x) {
  # silence xcolor
  x = sub('\\usepackage[]{color}', '\\usepackage{xcolor}', x, fixed = TRUE)
  # add an noindent after hooks -> remove blank line
  x = gsub('(\\\\end\\{knitrout\\}[\n]+)', '\\1\\\\noindent ', x)
  x
})

opts_chunk$set(
   fig.path = "knitr/figures/",
   #cache.path = "knitr/cache/",
   cache = FALSE,
   tidy = FALSE,
   #dev = 'tikz',
   external = TRUE,
   fig.align = "center",
   size = "scriptsize",
   stop = TRUE,
   fig.width = 9 * 0.8,
   fig.height = 6 * 0.8,
   small.mar = TRUE,
   prompt = TRUE
)
@
<<gatherSummary,include=FALSE>>=
ee = as.environment("package:mlr")
nl = table(sub("^makeRLearner\\.([[:alpha:]]+)\\..+", "\\1", methods("makeRLearner")))
nm = sapply(list(classif = listMeasures("classif"), regr = listMeasures("regr"), surv = listMeasures("surv"), cluster = listMeasures("cluster")), length) - 4
@
%% PART I
\begin{frame}
  \titlepage
\end{frame}

%\begin{vframe}{Overview}
%  \tableofcontents
%\end{vframe}
\section{The \pkg{mlr} Package}
\begin{vframe}{Motivation}
  \begin{blocki}{The good news}
  \item CRAN serves hundreds of packages for machine learning %(cf.\ CRAN task view machine learning)
  \item Many packages are compliant to the unwritten interface definition:
<<model-standard,eval=FALSE>>=
model = fit(target ~ ., data = train.data, ...)
predictions = predict(model, newdata = test.data, ...)
@
  \end{blocki}
  
  \begin{blocki}{The bad news}
    \item Some packages do not support the formula interface or their API is \enquote{just different}
    %\item Functionality is always package or model-dependent, even though the procedure might be general
    \item No meta-information available or buried in docs (sometimes not documented at all)
    %\item Many packages require the user to \enquote{guess} good hyperparameters
    \item Larger experiments lead to lengthy, tedious and error-prone code
  \end{blocki}
\end{vframe}


\begin{vframe}{Motivation: \pkg{mlr}}

    \oneliner{\url{https://github.com/mlr-org/mlr}}
    
  \begin{itemize}
    \item Unified interface for the basic building blocks: tasks, learners, resampling, hyperparameters, \ldots
    \item Reflections: nearly all objects are queryable (i.e.\ you can ask them for their properties and program on them)
    
    %\item Clear S3 interface to R classification, regression, clustering and survival analysis methods
    \item Possibility to fit, predict, evaluate and resample models
    %\item Easy extension mechanism through S3 inheritance
    %\item Abstract description of learners and tasks by properties
    %\item Parameter system for learners to encode data types and constraints
    %\item Many convenience methods and generic building blocks for your  machine learning experiments
    %\item Resampling like bootstrapping and cross-validation
    \item Different visualizations for e.g. ROC curves and predictions
    \item Benchmarking of learners for muliple data sets
    %\item Easy hyperparameter tuning using different optimization strategies%, including potent configurators like iterated F-racing (irace) or sequential model-based optimization
    %\item Variable selection with filters and wrappers
    %\item Nested resampling of models with tuning and feature selection
    %\item Cost-sensitive learning, threshold tuning and imbalance correction
    %\item Wrapper mechanism to extend learner functionality and complex and custom ways
    %\item Combine different processing steps to a complex data mining chain that can be jointly optimized
    %\item OpenML connector for the Open Machine Learning server
    %\item Extension points to integrate your own stuff
    \item Parallelization is built-in
    \item ...
  \end{itemize}
\end{vframe}


\begin{frame}[containsverbatim]{Task Abstractions}
  \begin{itemize}
    \item Regression, classification, survival and cost-sensitive tasks
    \item Internally: data frame with annotations: target column(s), weights, misclassification costs, \ldots)
  \end{itemize}
<<task>>=
data("Sonar", package = "mlbench")
task = makeClassifTask(data = Sonar, target = "Class")
print(task)
@
\end{frame}


\begin{frame}[containsverbatim]{Learner Abstractions}
  \begin{itemize}
    \item \Sexpr{nl["classif"]}~classification, \Sexpr{nl["regr"]}~regression, \Sexpr{nl["surv"]}~survival
    \item Internally: functions to train and predict%, parameter set and annotations 
  \end{itemize}
<<learner, size = "tiny">>=
lrn = makeLearner("classif.rpart")
print(lrn)
lrn = makeLearner("classif.rpart", predict.type = "prob")
print(lrn)
@
\end{frame}

%' \begin{frame}[containsverbatim]{Learner Abstractions}
%' <<parmset>>=
%' getParamSet(lrn)
%' @
%' 
%' \end{frame}

%' \begin{frame}[containsverbatim]{Performance Measures}
%' \begin{itemize}
%'   \item \Sexpr{nm["classif"]}~classification, \Sexpr{nm["regr"]}~regression, \Sexpr{nm["surv"]}~survival
%'   \item Internally: performance function, aggregation function and annotations
%' \end{itemize}
%' <<measure>>=
%' print(mmce)
%' print(timetrain)
%' @
%' \end{frame}


\begin{frame}[containsverbatim]{Resampling}
\begin{itemize}
  \item Resampling techniques: CV, Bootstrap, Subsampling, \ldots
<<rdesc>>=
cv3f = makeResampleDesc("CV", iters = 3, stratify = TRUE)
@
  \item 10-fold CV of rpart on iris
<<resample>>=
lrn = makeLearner("classif.rpart", predict.type = "prob")
cv10f = makeResampleDesc("CV", iters = 10)
measures = list(acc, auc)

resample(lrn, task, cv10f, measures)$aggr
@
\end{itemize}
\end{frame}



\begin{frame}[containsverbatim]{Benchmarking}
\begin{itemize}
  \item Compare multiple learners on multiple tasks
  \item Fair comparisons: same training and test sets for each learner
\end{itemize}
<<benchmark>>=
sonar.task = makeClassifTask(data = Sonar, target = "Class")
cv10f = makeResampleDesc("CV", iters = 10)
measures = list(acc, auc)
learners = list(
  makeLearner("classif.randomForest", predict.type = "prob"),
  makeLearner("classif.rpart", predict.type = "prob")
)

(res = benchmark(learners, sonar.task, cv10f, measures))
@

\end{frame}


\begin{frame}[containsverbatim]{Benchmarking}

<<benchmark2>>=
library(gridExtra)
grid.arrange(plotBenchmarkResult(res, auc, pretty.names = F), 
             plotBenchmarkResult(res, acc, pretty.names = F), ncol=2)
@

\end{frame}

\section{OpenML R-Package}
\begin{vframe}{OpenML R-Package}
  \oneliner{\url{https://github.com/openml/r}}
  \begin{blocki}{Current API in R}
    \item Explore data and tasks
    \item Download data and tasks
    \item Register learners
    \item Upload runs
    \item Explore your own and other people's results
  \end{blocki}

  \begin{center}
  Already nicely connected to \pkg{mlr}!
  \end{center}
\end{vframe}


\begin{vbframe}{OpenML: Explore and Select Data}
<<openml1, eval=OPENML_EVAL>>=
library(OpenML)
# You can get your own account at openml.org
authenticateUser(username = "openml.rteam@gmail.com", 
                 password = "testpassword")
listOMLDataSets()[1:3, 1:5]
@
\framebreak
<<openml1b, eval=OPENML_EVAL>>=
listOMLTasks()[1:3, 1:7]
@
\end{vbframe}

\begin{vframe}{OpenML: Download a Data Set}
<<openml2a, eval=OPENML_EVAL, message = FALSE>>=
# uses built in caching from disk
getOMLDataSet(1)
@
\end{vframe}

\begin{vbframe}{OpenML: Download a Task}
<<openml3, eval=OPENML_EVAL, message = FALSE>>=
# uses built in caching from disk
oml.task = getOMLTask(task.id = 1)
print(oml.task)
@
\framebreak
<<openml3b, eval=OPENML_EVAL, message = FALSE>>=
oml.task$input$data.set
oml.task$input$estimation.procedure
oml.task$input$evaluation.measures
@
\end{vbframe}

%' \begin{vframe}{OpenML: Run a Task}
%' <<openml4, eval=OPENML_EVAL, size="tiny">>=
%' lrn = makeLearner("classif.rpart")
%' res = runTaskMlr(oml.task, lrn)
%' @
%' \end{vframe}


\begin{vframe}{OpenML: Run several Learners on one Task}
<<openml4b, eval=OPENML_EVAL, message = FALSE, warning = FALSE>>=
lrn1 = makeLearner("classif.rpart")
lrn2 = makeLearner("classif.randomForest")
res = runMultipleLearnersOnTask(oml.task, list(lrn1, lrn2))
res$benchmark
@
\end{vframe}


\begin{vframe}{OpenML R-Package}
  \oneliner{Let's have a look at the R-Package}
  %\framebreak
\end{vframe}

% \begin{vframe}{OpenML R-Package}
% \oneliner{\url{https://github.com/openml/r}}
%   \begin{blocki}{Tutorial}
%     \item Stage 0: Explore and Select Data
%     \item Stage 1: Download a Data Set
%     \item Stage 2: Run a Task
%     \item Stage 3: Upload Learners
%     \item Explore your own and other people's results
%   \end{blocki}
% \end{vframe}

% \begin{frame}
%   \includegraphics[page=41,width=0.95\textwidth]{figure/oml-talk.pdf}
% \end{frame}
% 
% \section{The End}
% \begin{vframe}{There is more \ldots}
%   \begin{blocki*}
%   \item Regular cost-sensitive learning (class-specific costs)
%   \item Cost-sensitive learning (example-dependent costs)
%   \item Model-based optimization
%   \item Multi-criteria optimization
%   \item OpenML
%   \item \ldots
%   \end{blocki*}
% \end{vframe}
% 
% \begin{vframe}{Outlook}
%   \begin{blocki}{We are working on}
%   \item Even better tuning system
%   \item More interactive plots
%   \item Large-Scale SVM ensembles
%   \item Time-Series tasks
%   \item Better benchmark analysis
%   \item Multi-Label classification
%   \item \ldots
%   \end{blocki}
% \end{vframe}

\begin{vframe}
  \oneliner{Thanks!}
  \color{white}\cite{van2013openml} and \cite{vanschoren2014openml} 
\end{vframe}

\begin{frame}[allowframebreaks]
\frametitle{References}
\bibliographystyle{apalike}
\bibliography{../Bib}
\end{frame}

\end{document}
% vim: set spelllang=en :
